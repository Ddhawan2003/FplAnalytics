{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKbiN/W2O1v1yZW4KzMDNB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ddhawan2003/FplAnalytics/blob/main/KnapsackFPL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# Step 1: Load the existing CSV file\n",
        "csv_file_path = 'updated_players.csv'\n",
        "updated_players_df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Step 2: Fetch the player prices from the Fantasy Premier League API\n",
        "url = 'https://fantasy.premierleague.com/api/bootstrap-static/'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    players = data['elements']\n",
        "\n",
        "    # Create a dictionary to map player names to their now_cost\n",
        "    player_prices = {\n",
        "        f\"{player['first_name']} {player['second_name']}\": player['now_cost'] / 10.0  # Convert to millions\n",
        "        for player in players\n",
        "    }\n",
        "\n",
        "    # Update the prices in the DataFrame\n",
        "    updated_players_df['now_cost'] = updated_players_df['first_name'] + ' ' + updated_players_df['second_name']\n",
        "    updated_players_df['now_cost'] = updated_players_df['now_cost'].map(player_prices).fillna(updated_players_df['now_cost'])\n",
        "\n",
        "    # Step 3: Save the updated DataFrame back to CSV\n",
        "    updated_players_df.to_csv(csv_file_path, index=False)\n",
        "    print(\"Updated player prices successfully.\")\n",
        "else:\n",
        "    print(f\"Failed to retrieve data: {response.status_code}\")\n",
        "\n",
        "\n",
        "if 'price' in updated_players_df.columns:\n",
        "    updated_players_df.drop(columns=['now_cost'], inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbbQdsp8UYfw",
        "outputId": "66a3eb09-ccec-4d32-8355-c748f13c46b0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated player prices successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8e1YLYCCWCRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the player data from the CSV file\n",
        "players_df = pd.read_csv('cleaned_players.csv', delimiter=',')  # Change delimiter if necessary\n",
        "\n",
        "def calculate_predicted_points(row):\n",
        "    points = 0\n",
        "\n",
        "    # Minutes played points\n",
        "    if row['minutes'] >= 60:\n",
        "        points += 2\n",
        "    elif row['minutes'] > 0:\n",
        "        points += 1\n",
        "\n",
        "    # Goals scored points\n",
        "    if row['element_type'] == 'GK':\n",
        "        points += row['goals_scored'] * 10  # Goalkeeper goals\n",
        "        points += row['clean_sheets'] * 4  # Clean sheets for GK\n",
        "        points += row['goals_conceded'] // 2 * -1  # Goals conceded penalties\n",
        "        points += row['bps'] // 3  # Bonus points from BPS\n",
        "    elif row['element_type'] == 'DEF':\n",
        "        points += row['goals_scored'] * 6  # Defender goals\n",
        "        points += row['clean_sheets'] * 4  # Clean sheets for DEF\n",
        "        points += row['goals_conceded'] // 2 * -1  # Goals conceded penalties\n",
        "        points += row['bps'] // 3  # Bonus points from BPS\n",
        "    elif row['element_type'] == 'MID':\n",
        "        points += row['goals_scored'] * 5  # Midfielder goals\n",
        "        points += row['assists'] * 3  # Assists points for MID\n",
        "        points += row['clean_sheets'] * 1  # Clean sheets for MID\n",
        "        points += row['bps'] // 3  # Bonus points from BPS\n",
        "    elif row['element_type'] == 'FWD':\n",
        "        points += row['goals_scored'] * 4  # Forward goals\n",
        "        points += row['assists'] * 3  # Assists points for FWD\n",
        "        points += row['bps'] // 3  # Bonus points from BPS\n",
        "\n",
        "    # Penalties, cards, and own goals penalties\n",
        "    points += row['yellow_cards'] * -1\n",
        "    points += row['red_cards'] * -3\n",
        "\n",
        "    return points\n",
        "\n",
        "# Apply the function to each row to calculate predicted points\n",
        "players_df['predicted_points'] = players_df.apply(calculate_predicted_points, axis=1)\n",
        "\n",
        "# Save the updated DataFrame back to CSV\n",
        "players_df.to_csv('updated_players.csv', index=False)\n",
        "\n",
        "print(\"Predicted points have been calculated and saved to 'updated_players.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gxqz2nWRwPd",
        "outputId": "bb9c0063-d02b-492c-827f-09ca6f31df6d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted points have been calculated and saved to 'updated_players.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pulp\n",
        "\n",
        "# Load the updated_players.csv file\n",
        "csv_file_path = 'updated_players.csv'\n",
        "updated_players_df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Convert now_cost to price (the cost is in millions, so we divide by 10)\n",
        "updated_players_df['price'] = updated_players_df['now_cost']\n",
        "\n",
        "# Create a list of players with relevant information\n",
        "players = []\n",
        "for index, row in updated_players_df.iterrows():\n",
        "    players.append({\n",
        "        'name': f\"{row['first_name']} {row['second_name']}\",\n",
        "        'points': row['predicted_points'],\n",
        "        'price': row['price'],\n",
        "        'position': row['element_type'],  # Assuming element_type corresponds to position\n",
        "    })\n",
        "\n",
        "# Initialize the problem\n",
        "problem = pulp.LpProblem(\"Best_Premier_League_Team\", pulp.LpMaximize)\n",
        "\n",
        "# Create decision variables\n",
        "x = pulp.LpVariable.dicts(\"player\", range(len(players)), cat=\"Binary\")\n",
        "\n",
        "# Objective function: maximize total predicted points\n",
        "problem += pulp.lpSum([x[i] * players[i]['points'] for i in range(len(players))])\n",
        "\n",
        "# Budget constraint\n",
        "problem += pulp.lpSum([x[i] * players[i]['price'] for i in range(len(players))]) <= 100\n",
        "\n",
        "# Position constraints\n",
        "problem += pulp.lpSum([x[i] for i in range(len(players)) if players[i]['position'] == 'GK']) == 2\n",
        "problem += pulp.lpSum([x[i] for i in range(len(players)) if players[i]['position'] == 'DF']) <= 5\n",
        "problem += pulp.lpSum([x[i] for i in range(len(players)) if players[i]['position'] == 'MF']) <= 5\n",
        "problem += pulp.lpSum([x[i] for i in range(len(players)) if players[i]['position'] == 'FW']) <= 3\n",
        "\n",
        "# Solve the problem\n",
        "problem.solve()\n",
        "\n",
        "# Get the selected team\n",
        "selected_team = [players[i]['name'] for i in range(len(players)) if x[i].value() == 1]\n",
        "total_points = pulp.value(problem.objective)\n",
        "\n",
        "# Output the results\n",
        "print(f\"Selected team: {selected_team}\")\n",
        "print(f\"Total predicted points: {total_points}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qppwf0i7O7lp",
        "outputId": "2e04e211-e5d3-4695-827e-f005a0f5caa1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected team: ['Bryan Mbeumo', 'Danny Welbeck', 'Noni Madueke', 'Cole Palmer', 'Dwight McNeil', 'Emile Smith Rowe', 'Wilfred Ndidi', 'Alisson Ramses Becker', 'Ibrahima Konaté', 'Luis Díaz', 'Virgil van Dijk', 'Mateo Kovačić', 'Diogo Dalot Teixeira', 'André Onana', 'James Maddison', 'Cristian Romero']\n",
            "Total predicted points: 1217.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Load the data\n",
        "file_path = 'merged_gw.csv'  # Update this to your CSV file path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "# Convert 'kickoff_time' to datetime format\n",
        "data['kickoff_time'] = pd.to_datetime(data['kickoff_time'])\n",
        "\n",
        "# Sort by player and time\n",
        "data.sort_values(by=['name', 'kickoff_time'], inplace=True)\n",
        "\n",
        "# Calculate rolling averages for relevant features\n",
        "data['rolling_xP'] = data.groupby('name')['xP'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "data['rolling_assists'] = data.groupby('name')['assists'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "data['rolling_goals'] = data.groupby('name')['goals_scored'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "data['rolling_bonus'] = data.groupby('name')['bonus'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "data['rolling_clean_sheets'] = data.groupby('name')['clean_sheets'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "\n",
        "# Step 3: Create the feature set (X) and target variable (y)\n",
        "# Select features for the model\n",
        "features = ['rolling_xP', 'rolling_assists', 'rolling_goals',\n",
        "            'rolling_bonus', 'rolling_clean_sheets', 'bps',\n",
        "            'creativity', 'threat', 'minutes', 'position']  # Add more features as necessary\n",
        "\n",
        "# Convert categorical variable (position) to dummy/indicator variables\n",
        "X = pd.get_dummies(data[features], drop_first=True)\n",
        "\n",
        "# Target variable: points for the next game week\n",
        "data['next_gw_points'] = data['total_points'].shift(-1)\n",
        "\n",
        "y = data['next_gw_points'].dropna()\n",
        "\n",
        "# Align X with y\n",
        "X = X.iloc[:-1]  # Remove the last row which will not have a target variable\n",
        "\n",
        "# Step 4: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Train the Random Forest model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Make predictions for the next game week (GW8)\n",
        "y_pred = rf_model.predict(X)\n",
        "\n",
        "# Create a DataFrame for predictions\n",
        "predictions = pd.DataFrame({\n",
        "    'Player': data['name'].iloc[:-1],  # Exclude the last row which doesn't have a target\n",
        "    'Predicted Points': y_pred\n",
        "})\n",
        "\n",
        "# Step 7: Display the top players with the most predicted points for GW8\n",
        "top_predictions = predictions.sort_values(by='Predicted Points', ascending=False)\n",
        "\n",
        "# Display the top 10 players\n",
        "print(\"Top 10 Players Predicted Points for GW8:\")\n",
        "print(top_predictions.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5Gr8stiYX7m",
        "outputId": "3a4975c2-2ab1-4d3b-e8df-ecb106717641"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Players Predicted Points for GW8:\n",
            "               Player  Predicted Points\n",
            "2563      Cole Palmer             18.43\n",
            "2369        Luis Díaz             13.97\n",
            "232    Erling Haaland             13.36\n",
            "3819  Michail Antonio             13.00\n",
            "13        Cole Palmer             12.25\n",
            "1070        Luis Díaz             11.83\n",
            "757     Mohamed Salah             11.83\n",
            "2047  Nicolas Jackson             11.63\n",
            "851    Erling Haaland             11.42\n",
            "3504      Bukayo Saka             11.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Step 1: Load current season data\n",
        "current_file_path = 'merged_gw.csv'  # Update with your current season CSV file path\n",
        "current_data = pd.read_csv(current_file_path)\n",
        "\n",
        "# Step 2: Load last season's performance data\n",
        "last_season_file_path = 'merged_gw (1).csv'  # Update with your last season CSV file path\n",
        "last_season_data = pd.read_csv(last_season_file_path)\n",
        "\n",
        "# Step 3: Preprocess last season's data\n",
        "last_season_data['rolling_xP'] = last_season_data.groupby('name')['xP'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "last_season_data['rolling_assists'] = last_season_data.groupby('name')['assists'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "last_season_data['rolling_goals'] = last_season_data.groupby('name')['goals_scored'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "last_season_data['rolling_bonus'] = last_season_data.groupby('name')['bonus'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "last_season_data['rolling_clean_sheets'] = last_season_data.groupby('name')['clean_sheets'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "\n",
        "# Step 4: Select relevant features from last season's data\n",
        "last_season_features = last_season_data[['name', 'rolling_xP', 'rolling_assists', 'rolling_goals', 'rolling_bonus', 'rolling_clean_sheets']]\n",
        "\n",
        "# Step 5: Merge last season's features with current season data\n",
        "current_data = current_data.merge(last_season_features, on='name', how='left', suffixes=('', '_last_season'))\n",
        "\n",
        "# Step 6: Preprocess current season data\n",
        "if 'kickoff_time' in current_data.columns:\n",
        "    current_data['kickoff_time'] = pd.to_datetime(current_data['kickoff_time'])\n",
        "\n",
        "# Calculate rolling averages for current season features\n",
        "current_data['rolling_xP_current'] = current_data.groupby('name')['xP'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "\n",
        "# Step 7: Create the feature set (X) and target variable (y)\n",
        "features = [\n",
        "    'rolling_xP',\n",
        "    'rolling_assists',\n",
        "    'rolling_goals',\n",
        "    'rolling_bonus',\n",
        "    'rolling_clean_sheets',\n",
        "    'rolling_xP_current',\n",
        "    'bps',\n",
        "    'creativity',\n",
        "    'threat',\n",
        "    'minutes',\n",
        "    'position'  # Removed 'fixture_strength'\n",
        "]\n",
        "\n",
        "# Convert categorical variable (position) to dummy/indicator variables\n",
        "X = pd.get_dummies(current_data[features], drop_first=True)\n",
        "\n",
        "# Step 8: Create target variable: points for the next game week\n",
        "current_data['next_gw_points'] = current_data['total_points'].shift(-1)\n",
        "\n",
        "# Ensure there are no NaNs in the target variable\n",
        "current_data.dropna(subset=['next_gw_points'], inplace=True)\n",
        "\n",
        "# Align y with X\n",
        "y = current_data['next_gw_points']\n",
        "X = X.loc[y.index]  # Align X with y indices\n",
        "\n",
        "# Step 9: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 10: Train the Random Forest model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model performance\n",
        "y_train_pred = rf_model.predict(X_train)\n",
        "y_test_pred = rf_model.predict(X_test)\n",
        "\n",
        "print(\"Training MSE:\", mean_squared_error(y_train, y_train_pred))\n",
        "print(\"Testing MSE:\", mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "# Step 11: Make predictions for the next game week (GW8)\n",
        "y_pred = rf_model.predict(X)\n",
        "\n",
        "# Create a DataFrame for predictions\n",
        "predictions = pd.DataFrame({\n",
        "    'Player': current_data['name'],  # Use all rows\n",
        "    'Predicted Points': y_pred\n",
        "})\n",
        "\n",
        "# Step 11: Display the top players with the most predicted points for GW8\n",
        "top_predictions = predictions.sort_values(by='Predicted Points', ascending=False)\n",
        "\n",
        "# Step 12: Save the top 100 unique predictions into a CSV file\n",
        "top_100_unique_names = top_predictions.drop_duplicates('Player').head(100)\n",
        "\n",
        "# Save to CSV\n",
        "output_file_path = 'top_100_player_predictions.csv'  # Path to save the CSV file\n",
        "top_100_unique_names.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f\"Top 100 unique player predictions saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvwa70y4dnwb",
        "outputId": "7ea34623-9150-4b05-bdc8-68067a7e61b7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MSE: 0.16423303414911494\n",
            "Testing MSE: 0.49920316519307295\n",
            "Top 100 unique player predictions saved to top_100_player_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Fetch the fixtures data from the Fantasy Premier League API\n",
        "fixtures_url = \"https://fantasy.premierleague.com/api/fixtures/\"\n",
        "response = requests.get(fixtures_url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    fixtures_data = response.json()  # Parse JSON response\n",
        "else:\n",
        "    print(\"Failed to retrieve fixtures data:\", response.status_code)\n",
        "    fixtures_data = []\n",
        "\n",
        "# Step 2: Fetch the events data\n",
        "events_url = \"https://fantasy.premierleague.com/api/events/\"\n",
        "events_response = requests.get(events_url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if events_response.status_code == 200:\n",
        "    events_data = events_response.json()  # Parse JSON response\n",
        "else:\n",
        "    print(\"Failed to retrieve events data:\", events_response.status_code)\n",
        "    events_data = []\n",
        "\n",
        "# Step 3: Extract relevant fixture information for GW8\n",
        "gw8_fixtures = []\n",
        "\n",
        "# Fetch GW8 event ID\n",
        "gw8_event_id = next((event['id'] for event in events_data if event['name'] == \"Gameweek 8\"), None)\n",
        "\n",
        "if gw8_event_id is not None:\n",
        "    # Iterate through the fixtures data\n",
        "    for fixture in fixtures_data:\n",
        "        if fixture['event'] == gw8_event_id:  # Filter for GW8\n",
        "            fixture_info = {\n",
        "                'Fixture ID': fixture['id'],\n",
        "                'Home Team': fixture['team_a'],\n",
        "                'Away Team': fixture['team_h'],\n",
        "                'Kickoff Time': fixture['kickoff_time'],\n",
        "                'Venue': fixture.get('venue', 'N/A'),\n",
        "                'Home Team Score': fixture.get('team_a_score', None),\n",
        "                'Away Team Score': fixture.get('team_h_score', None),\n",
        "            }\n",
        "            gw8_fixtures.append(fixture_info)\n",
        "else:\n",
        "    print(\"Gameweek 8 not found in events data.\")\n",
        "\n",
        "# Step 4: Convert GW8 fixtures to a DataFrame\n",
        "gw8_fixtures_df = pd.DataFrame(gw8_fixtures)\n",
        "\n",
        "# Step 5: Save the DataFrame to a CSV file\n",
        "csv_file_path = 'gw8_fixtures.csv'\n",
        "gw8_fixtures_df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"GW8 fixtures saved to {csv_file_path}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1O0F2UcglvJ",
        "outputId": "72de633a-bd27-4157-ecec-733f1a90d7a8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GW8 fixtures saved to gw8_fixtures.csv.\n"
          ]
        }
      ]
    }
  ]
}